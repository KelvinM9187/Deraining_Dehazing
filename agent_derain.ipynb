{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMC2cJmJ1d0OzEiILOL5MDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KelvinM9187/Deraining_Dehazing/blob/main/agent_derain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HBHedFJuBn1A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK2XSMwyCBqK",
        "outputId": "539c76f8-9f07-49db-b0ad-135ac9901484"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)"
      ],
      "metadata": {
        "id": "Biz8EYbVCQjj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureFusion(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(FeatureFusion, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(channels*2, channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x2_resized = F.interpolate(x2, size=x1.shape[2:], mode='bilinear', align_corners=False)\n",
        "        fused = torch.cat([x1, x2_resized], dim=1)\n",
        "        return self.conv(fused)"
      ],
      "metadata": {
        "id": "KrUWdhLKCZNc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DehazeDerainNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, base_channels=32):\n",
        "        super(DehazeDerainNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, base_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(base_channels*4, base_channels*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Bottleneck with attention\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(base_channels*4, base_channels*8, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ChannelAttention(base_channels*8),\n",
        "            nn.Conv2d(base_channels*8, base_channels*8, 3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels*8),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder with feature fusion\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels*8, base_channels*4, 2, stride=2)\n",
        "        self.dec1 = FeatureFusion(base_channels*4)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 2, stride=2)\n",
        "        self.dec2 = FeatureFusion(base_channels*2)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels*2, base_channels, 2, stride=2)\n",
        "        self.dec3 = FeatureFusion(base_channels)\n",
        "\n",
        "        # Output\n",
        "        self.out_conv = nn.Conv2d(base_channels, out_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(e3)\n",
        "\n",
        "        # Decoder\n",
        "        d1 = self.up1(b)\n",
        "        d1 = self.dec1(d1, e3)\n",
        "\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = self.dec2(d2, e2)\n",
        "\n",
        "        d3 = self.up3(d2)\n",
        "        d3 = self.dec3(d3, e1)\n",
        "\n",
        "        return torch.sigmoid(self.out_conv(d3))\n",
        ""
      ],
      "metadata": {
        "id": "T4OxpwHmCevc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Custom Dataset Class for your specific structure\n",
        "class CombinedHazeRainDataset(Dataset):\n",
        "    def __init__(self, rain_path, no_rain_path, haze_path, no_haze_path, transform=None, patch_size=128, mode='train'):\n",
        "        self.transform = transform\n",
        "        self.patch_size = patch_size\n",
        "        self.mode = mode\n",
        "\n",
        "        # Load Rain100 data\n",
        "        self.rain_images = sorted([os.path.join(rain_path, f) for f in os.listdir(rain_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        self.no_rain_images = sorted([os.path.join(no_rain_path, f) for f in os.listdir(no_rain_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "        # Load RESIDE data\n",
        "        self.haze_images = sorted([os.path.join(haze_path, f) for f in os.listdir(haze_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        self.no_haze_images = sorted([os.path.join(no_haze_path, f) for f in os.listdir(no_haze_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "        # Combine all samples\n",
        "        self.degraded_images = self.rain_images + self.haze_images\n",
        "        self.clean_images = self.no_rain_images + self.no_haze_images\n",
        "\n",
        "        # For validation, let's take 20% of the data\n",
        "        if mode == 'val':\n",
        "            self.degraded_images = self.degraded_images[:int(0.2*len(self.degraded_images))]\n",
        "            self.clean_images = self.clean_images[:int(0.2*len(self.clean_images))]\n",
        "        elif mode == 'train':\n",
        "            self.degraded_images = self.degraded_images[int(0.2*len(self.degraded_images)):]\n",
        "            self.clean_images = self.clean_images[int(0.2*len(self.clean_images)):]\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.degraded_images), len(self.clean_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        degraded_img = Image.open(self.degraded_images[idx]).convert('RGB')\n",
        "        clean_img = Image.open(self.clean_images[idx]).convert('RGB')\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        degraded_img = np.array(degraded_img)\n",
        "        clean_img = np.array(clean_img)\n",
        "\n",
        "        # Random crop to patch_size\n",
        "        h, w = degraded_img.shape[:2]\n",
        "        if h > self.patch_size and w > self.patch_size:\n",
        "            top = np.random.randint(0, h - self.patch_size)\n",
        "            left = np.random.randint(0, w - self.patch_size)\n",
        "            degraded_img = degraded_img[top:top+self.patch_size, left:left+self.patch_size]\n",
        "            clean_img = clean_img[top:top+self.patch_size, left:left+self.patch_size]\n",
        "\n",
        "        if self.transform:\n",
        "            degraded_img = self.transform(degraded_img)\n",
        "            clean_img = self.transform(clean_img)\n",
        "        else:\n",
        "            degraded_img = transforms.ToTensor()(degraded_img)\n",
        "            clean_img = transforms.ToTensor()(clean_img)\n",
        "\n",
        "        return degraded_img, clean_img\n"
      ],
      "metadata": {
        "id": "1uMa8U3QDbrC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training Function\n",
        "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-4, device='cuda'):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for degraded, clean in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
        "            degraded = degraded.to(device)\n",
        "            clean = clean.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(degraded)\n",
        "            loss = criterion(outputs, clean)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * degraded.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for degraded, clean in val_loader:\n",
        "                degraded = degraded.to(device)\n",
        "                clean = clean.to(device)\n",
        "                outputs = model(degraded)\n",
        "                val_loss += criterion(outputs, clean).item() * degraded.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
        "\n",
        "          # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/best_model.pth')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "upWnxE7ZD5Vh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Main Execution\n",
        "if __name__ == '__main__':\n",
        "    # Parameters\n",
        "    batch_size = 8  # Reduced for Colab memory\n",
        "    patch_size = 128\n",
        "    base_channels = 32  # Reduced from original paper for Colab compatibility\n",
        "    epochs = 10  # Start with fewer epochs\n",
        "\n",
        "    # Define paths to your data in Google Drive\n",
        "    rain_path = '/content/drive/MyDrive/Datasets/Rain100/Rain100L/rain'\n",
        "    no_rain_path = '/content/drive/MyDrive/Datasets/Rain100/Rain100L/norain'\n",
        "    haze_path = '/content/drive/MyDrive/Datasets/RESIDE/SOTS/outdoor/hazy'\n",
        "    no_haze_path = '/content/drive/MyDrive/Datasets/RESIDE/SOTS/outdoor/gt'\n",
        "\n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CombinedHazeRainDataset(\n",
        "        rain_path=rain_path,\n",
        "        no_rain_path=no_rain_path,\n",
        "        haze_path=haze_path,\n",
        "        no_haze_path=no_haze_path,\n",
        "        transform=transform,\n",
        "        patch_size=patch_size,\n",
        "        mode='train'\n",
        "    )\n",
        "\n",
        "    val_dataset = CombinedHazeRainDataset(\n",
        "        rain_path=rain_path,\n",
        "        no_rain_path=no_rain_path,\n",
        "        haze_path=haze_path,\n",
        "        no_haze_path=no_haze_path,\n",
        "        transform=transform,\n",
        "        patch_size=patch_size,\n",
        "        mode='val'\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "      # Initialize model\n",
        "    model = DehazeDerainNet(base_channels=base_channels)\n",
        "\n",
        "    # Check if GPU is available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Train\n",
        "    trained_model = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        epochs=epochs,\n",
        "        lr=1e-4,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"Training completed! Best model saved to Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ_uf97pEXLU",
        "outputId": "e9f52f54-f0b7-439d-e767-0bd35343c020"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 60/60 [03:32<00:00,  3.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.547689, Val Loss: 0.535294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 60/60 [00:10<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.477021, Val Loss: 0.520684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 60/60 [00:10<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.443040, Val Loss: 0.481254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 60/60 [00:10<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.430678, Val Loss: 0.438056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 60/60 [00:09<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.390097, Val Loss: 0.465636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 60/60 [00:09<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.386475, Val Loss: 0.440647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 60/60 [00:09<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.390119, Val Loss: 0.439704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 60/60 [00:10<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 0.372243, Val Loss: 0.462875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 60/60 [00:10<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.378464, Val Loss: 0.457064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 60/60 [00:10<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.344939, Val Loss: 0.418690\n",
            "Training completed! Best model saved to Google Drive.\n"
          ]
        }
      ]
    }
  ]
}